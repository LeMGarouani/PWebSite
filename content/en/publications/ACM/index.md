---
title: "A Survey and Perspective View of Meta-Learning for Automated Algorithms Selection and Parametrization"
date:  "2024-03-02"
information: "Artificial Intelligence Review"
category: 1 # 1: article, 2: conference, 3: softwares, 4: others
contributors: ["Moncef Garouani", "Adeel Ahmad", "Mourad Bouneffa"]
doi: "10.21203/rs.3.rs-4106982/v1"
status: 1
---

# Abstract
<p style='text-align: justify;'>
Considerable progress has been made in the recent literature studies to tackle the Algorithms Selection and Parametrization (ASP) problem, which is diversified in multiple meta-learning setups. Yet there is a lack of surveys and comparative evaluations that critically analyze, summarize and assess the performance of existing methods. In this paper, we provide an overview of the state of the art in this continuously evolving field. The survey sheds light on the motivational reasons for pursuing classifiers selection through meta-learning. In this regard, Automated Machine Learning (AutoML) is usually treated as an ASP problem under the umbrella of the democratization of machine learning. Accordingly, AutoML makes machine learning techniques accessible to domain scientists who are interested in applying advanced analytics but lack the required expertise. It can ease the task of manually selecting ML algorithms and tuning related hyperparame-ters. We comprehensively discuss the different phases of classifiers selection based on a generic framework that is formed as an outcome of reviewing prior works. Subsequently, we propose a benchmark knowledge base of 4 millions previously learned models and present extensive comparative evaluations of the prominent methods for classifiers selection based on 08 classification algorithms and 400 benchmark datasets. The comparative study quantitatively assesses the performance of algorithms selection methods along while emphasizing the strengths and limitations of existing studies.
</p>
